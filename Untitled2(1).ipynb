{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ln = list()\n",
    "with open(r\"C:\\Users\\Zak\\Desktop\\tours\\ln.json\", \"r\", encoding=\"utf8\") as inputfile:\n",
    "    ln = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for mail in ln:\n",
    "    mail[\"texte\"] = re.sub(r\".+\\n+div.+\\n+.+\\n+.+\\n.+\\n.+\\n+\", r\"\", mail[\"texte\"])\n",
    "    mail[\"texte\"] = re.sub(r\"\\S*\\@\\S*\\s?\", r\" \", mail[\"texte\"])\n",
    "    mail[\"texte\"] = re.sub(r\"http\\S+\", r\" \", mail[\"texte\"])\n",
    "    mail[\"texte\"] = re.sub(r\"\\s+\", \" \", mail[\"texte\"])\n",
    "    mail[\"texte\"] = mail[\"texte\"][:-465]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"french\")\n",
    "stop_words.append(\"avoir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mail in ln:\n",
    "    doc = nlp(mail[\"texte\"])\n",
    "    texte_lemmatise = str()\n",
    "    sacdemots = list()\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        texte_lemmatise = texte_lemmatise + \" \" + lemma\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        elif lemma not in stop_words and len(lemma) > 4 :\n",
    "            sacdemots.append(lemma.lower())\n",
    "    mail[\"texte_lemmatise\"] = texte_lemmatise\n",
    "    mail[\"sacdemots\"] = sacdemots\n",
    "    \n",
    "    lieux = list()\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"LOC\" and ent.text != \"\\n\":\n",
    "            lieux.append(ent.text)\n",
    "    mail[\"lieux\"] = lieux\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bonjour', 'maison', 'science', 'homme', 'lorraine', 'chercher', 'ingénieur', 'informatique', 'aussi', 'possible', 'durer', 'contrat', 'mission', 'consister', 'principalement', 'miser', 'former', 'informatique', 'donnée', 'produire', 'cadrer', 'recherche', 'science', 'humain', 'sociale', 'corpus', 'texte', 'image', 'vidéo', 'hébergement', 'interrogation', 'ingénieur', 'devoir', 'notamment', 'développer', 'portail', 'centrer', 'ressource', 'mettre', 'donnée', 'former', 'hébergement', 'diffusion', 'travailler', 'concepteur', 'donnée', 'développer', 'outil', 'traitement', 'donnée', 'développer', 'outil', 'exploitation', 'consultation', 'ensemble', 'donnée', 'poster', 'pouvoir', 'baser', 'nancy', 'nécessiter', 'présence', 'placer', 'travail', 'distancer', 'possible', 'merci', 'envoyer', 'candidature']\n"
     ]
    }
   ],
   "source": [
    "sac = ln[0][\"sacdemots\"]\n",
    "print(sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm_data = list()\n",
    "\n",
    "for mail in ln:\n",
    "    sdm_data.append(mail[\"sacdemots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zak\\Anaconda3\\envs\\tours_clean\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.010*\"rechercher\" + 0.009*\"stage\" + 0.009*\"automatique\" + 0.008*\"langue\"')\n",
      "(1, '0.012*\"research\" + 0.011*\"language\" + 0.009*\"position\" + 0.009*\"dater\"')\n",
      "(2, '0.014*\"donnée\" + 0.010*\"rechercher\" + 0.008*\"projet\" + 0.007*\"informatique\"')\n",
      "(3, '0.010*\"research\" + 0.009*\"language\" + 0.008*\"position\" + 0.008*\"application\"')\n",
      "(4, '0.009*\"dater\" + 0.007*\"learning\" + 0.007*\"language\" + 0.005*\"machiner\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(sdm_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in sdm_data]\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mail in ln:\n",
    "    text = mail[\"texte_lemmatise\"]\n",
    "    keywords = gensim.summarization.keywords(text, words=5)\n",
    "    mail[\"keywords\"] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Zak\\Desktop\\tours\\ln_processed.json\", \"w\", encoding=\"utf8\") as outputfile:\n",
    "    ln = json.dump(ln, outputfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
